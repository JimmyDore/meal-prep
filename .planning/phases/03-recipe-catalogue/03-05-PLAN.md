---
phase: 03-recipe-catalogue
plan: 05
type: execute
wave: 2
depends_on: ["03-04"]
files_modified: []
autonomous: false
gap_closure: true
user_setup:
  - service: vps
    why: "Production environment needs PIPELINE_TOKEN set and data uploaded"
    env_vars:
      - name: PIPELINE_TOKEN
        source: "Generate with: openssl rand -hex 32"
    dashboard_config:
      - task: "Add PIPELINE_TOKEN to VPS .env file"
        location: "SSH to VPS -> /home/jimmydore/meal-prep/.env"

must_haves:
  truths:
    - "Recipe catalogue is accessible on mealprep.jimmydore.fr/recipes in production with HTTPS"
    - "Recipe detail pages load with image, macros, ingredients, and Jow link on production"
    - "Production database has the Phase 2 schema (11 recipe columns) applied"
    - "Production database has recipe data to display"
  artifacts:
    - path: "VPS:/home/jimmydore/meal-prep/.env"
      provides: "PIPELINE_TOKEN value for production"
      contains: "PIPELINE_TOKEN"
  key_links:
    - from: "docker-compose.prod.yml"
      to: "VPS .env"
      via: "docker-compose reads PIPELINE_TOKEN from .env and passes to app container"
      pattern: "PIPELINE_TOKEN"
    - from: ".github/workflows/deploy.yml"
      to: "drizzle/0001_crazy_husk.sql"
      via: "deploy script applies migration to prod DB"
      pattern: "drizzle_migrations"
---

<objective>
Deploy the code fixes from Plan 04 to production, verify the production app works, and populate the production database with recipe data.

Purpose: Complete the gap closure by deploying fixes, applying migrations, and seeding production data so mealprep.jimmydore.fr/recipes returns a working recipe catalogue.

Output: Production app serving recipe catalogue at mealprep.jimmydore.fr/recipes with real recipe data.
</objective>

<execution_context>
@/Users/jimmydore/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jimmydore/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/debug/prod-500-recipes.md
@.planning/phases/03-recipe-catalogue/03-UAT.md
@.planning/phases/03-recipe-catalogue/03-04-SUMMARY.md
@docker-compose.prod.yml
@.github/workflows/deploy.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Push code fixes and trigger deploy</name>
  <files></files>
  <action>
    1. Ensure Plan 04 changes are committed (docker-compose.prod.yml, src/lib/env.ts, .github/workflows/deploy.yml).

    2. Push to main to trigger CI/CD:
       ```bash
       git push origin main
       ```

    3. Monitor CI/CD pipeline:
       ```bash
       gh run watch
       ```
       Wait for the deploy to complete. The deploy script will now:
       - Pull the code with the 3 fixes
       - Build the new Docker image (with optional PIPELINE_TOKEN)
       - Start containers
       - Apply pending migrations (0000 + 0001) via the new migration loop
       - Prune old images

    4. If CI/CD fails, check logs:
       ```bash
       gh run view --log-failed
       ```
  </action>
  <verify>
    `gh run list --limit 1` shows the latest run with status "completed" and conclusion "success".
  </verify>
  <done>Code fixes deployed to production. CI/CD pipeline passes. Migration step executed on prod DB.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Plan 04 fixed 3 root causes of the production 500 error:
    1. PIPELINE_TOKEN added to docker-compose.prod.yml
    2. PIPELINE_TOKEN made optional in env.ts
    3. Auto-migration step added to deploy script

    Task 1 pushed and deployed these fixes to production.

    BEFORE verifying, the user MUST set PIPELINE_TOKEN on the VPS:
    ```bash
    ssh jimmydore@mealprep.jimmydore.fr
    cd /home/jimmydore/meal-prep
    echo "PIPELINE_TOKEN=$(openssl rand -hex 32)" >> .env
    docker compose -f docker-compose.prod.yml up -d
    ```
    (Note: PIPELINE_TOKEN is now optional for browsing, but required for future pipeline uploads. Set it now to avoid forgetting.)
  </what-built>
  <how-to-verify>
    1. Visit https://mealprep.jimmydore.fr/recipes -- should return 200 (page loads, may show 0 recipes if data not yet uploaded)
    2. Check the page does NOT show a 500 error
    3. If 0 recipes shown, that's expected -- data upload is the next task
    4. Check `gh run list --limit 1` shows successful deploy
  </how-to-verify>
  <resume-signal>Type "approved" if /recipes loads without 500 error, or describe issues if it still fails</resume-signal>
</task>

<task type="auto">
  <name>Task 3: Upload recipe data to production</name>
  <files></files>
  <action>
    Upload the locally enriched recipe data to the production server.

    1. First, check how many enriched recipes are available locally:
       ```bash
       wc -l data/enriched/*.jsonl
       ```

    2. Get the PIPELINE_TOKEN from the VPS (the user just set it):
       Ask the user for the PIPELINE_TOKEN value, or instruct them to retrieve it:
       ```bash
       ssh jimmydore@mealprep.jimmydore.fr "grep PIPELINE_TOKEN /home/jimmydore/meal-prep/.env"
       ```

    3. Run the upload script against production:
       ```bash
       PIPELINE_TOKEN=<token_from_vps> pnpm tsx scripts/pipeline/upload.ts --url https://mealprep.jimmydore.fr
       ```

       If the upload script does not support a `--url` flag, check the script source. It may use an environment variable like `API_URL` or `UPLOAD_URL`. Read `scripts/pipeline/upload.ts` to determine the correct invocation.

       Alternative approach if the script only targets localhost:
       - Modify the script temporarily or use environment variable override
       - Or run the upload from the VPS itself if enriched data is available there

    4. Verify recipe count in production:
       ```bash
       curl -s https://mealprep.jimmydore.fr/api/recipes | jq '.total // .data | length'
       ```
       Or simply visit https://mealprep.jimmydore.fr/recipes and count visible recipes.
  </action>
  <verify>
    Visit https://mealprep.jimmydore.fr/recipes -- recipe cards are visible with images, titles, and tags.
  </verify>
  <done>Production database has recipe data. Recipe catalogue displays recipes with images from Jow CDN.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Complete production deployment:
    - Code fixes deployed (PIPELINE_TOKEN, optional env, auto-migrations)
    - Migrations applied to production DB (11 new recipe columns)
    - Recipe data uploaded to production
  </what-built>
  <how-to-verify>
    1. Visit https://mealprep.jimmydore.fr/recipes -- recipe grid with images, search, filters, pagination
    2. Use the search bar to filter recipes
    3. Click a tag badge to filter by tag
    4. Click a recipe card -- detail page shows image, macros per serving, ingredients, Jow link
    5. Click "Voir sur Jow" -- opens Jow recipe in new tab
    6. Navigate to https://mealprep.jimmydore.fr/recipes/99999 -- shows 404 page with "Retour au catalogue" link
    7. Navigate to https://mealprep.jimmydore.fr/ -- redirects to /recipes

    This re-validates UAT tests 1-9 and 12-13 on production.
  </how-to-verify>
  <resume-signal>Type "approved" if all production tests pass, or describe remaining issues</resume-signal>
</task>

</tasks>

<verification>
1. `gh run list --limit 1` shows successful deploy
2. https://mealprep.jimmydore.fr/recipes returns 200 with recipe grid
3. https://mealprep.jimmydore.fr/recipes/[valid-id] returns recipe detail with macros
4. Recipe images load from Jow CDN
5. Search, tag filters, and pagination work on production
</verification>

<success_criteria>
- Production app does not return 500 on any page
- Recipe catalogue displays recipes with images, search, filters, pagination
- Recipe detail pages show macros, ingredients, Jow link
- UAT tests 12 and 13 pass on production
</success_criteria>

<output>
After completion, create `.planning/phases/03-recipe-catalogue/03-05-SUMMARY.md`
</output>
