---
phase: 02-recipe-data-pipeline
plan: 04
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/app/api/recipes/upload/route.ts
  - src/lib/env.ts
autonomous: true

must_haves:
  truths:
    - "POST /api/recipes/upload accepts a JSON recipe payload and persists it to the database"
    - "Endpoint validates bearer token from Authorization header against PIPELINE_TOKEN env var"
    - "Endpoint validates request body with Zod schema (rejects malformed data with 400)"
    - "Endpoint upserts recipe by jowId (no duplicates, updates existing data)"
    - "Endpoint upserts ingredients by name and links to recipe via recipe_ingredients junction"
    - "Endpoint upserts tags and links to recipe via recipe_tags junction"
    - "Endpoint returns 201 with { id } on success, 401 on bad auth, 400 on validation error"
  artifacts:
    - path: "src/app/api/recipes/upload/route.ts"
      provides: "POST endpoint for recipe upload with auth, validation, upsert"
      exports: ["POST"]
      min_lines: 80
  key_links:
    - from: "src/app/api/recipes/upload/route.ts"
      to: "src/db/schema/recipes.ts"
      via: "Drizzle insert with onConflictDoUpdate"
      pattern: "onConflictDoUpdate"
    - from: "src/app/api/recipes/upload/route.ts"
      to: "src/db/schema/ingredients.ts"
      via: "Drizzle insert ingredients with upsert on name"
      pattern: "ingredients.*onConflict"
    - from: "src/app/api/recipes/upload/route.ts"
      to: "process.env.PIPELINE_TOKEN"
      via: "Bearer token auth check"
      pattern: "PIPELINE_TOKEN|Bearer"
---

<objective>
Build the POST /api/recipes/upload endpoint that receives enriched recipe data, validates the bearer token, validates the payload with Zod, and upserts the recipe with all its ingredients and tags into the database using Drizzle transactions.

Purpose: This is the server-side data landing zone -- the pipeline's upload step sends enriched recipes here, and this endpoint ensures they are persisted correctly with deduplication.
Output: Next.js route handler at src/app/api/recipes/upload/route.ts
</objective>

<execution_context>
@/Users/jimmydore/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jimmydore/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-recipe-data-pipeline/02-RESEARCH.md
@.planning/phases/02-recipe-data-pipeline/02-CONTEXT.md
@.planning/phases/02-recipe-data-pipeline/02-01-SUMMARY.md
@src/db/schema/recipes.ts
@src/db/schema/ingredients.ts
@src/db/schema/tags.ts
@src/db/schema/common.ts
@src/db/index.ts
@src/lib/env.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create recipe upload API endpoint with auth, validation, and upsert</name>
  <files>
    src/app/api/recipes/upload/route.ts
  </files>
  <action>
1. **Create `src/app/api/recipes/upload/route.ts`** -- POST endpoint:

   **Bearer token authentication:**
   - Extract `Authorization` header, check it starts with "Bearer "
   - Compare token against `env.PIPELINE_TOKEN` (import from `@/lib/env`)
   - Return 401 `{ error: "Unauthorized" }` if missing or invalid

   **Zod request body validation:**
   Define schemas inline (or in a shared location) for the upload payload:
   ```
   ingredientUploadSchema = z.object({
     name: z.string().min(1),
     quantity: z.number().nullable(),
     unit: z.string().nullable(),
     originalText: z.string().nullable(),
     proteinPer100g: z.number().min(0).max(100).nullable(),
     carbsPer100g: z.number().min(0).max(100).nullable(),
     fatPer100g: z.number().min(0).max(100).nullable(),
     caloriesPer100g: z.number().min(0).max(900).nullable(),
     confidence: z.enum(["high", "medium", "low"]).nullable(),
   })

   recipeUploadSchema = z.object({
     jowId: z.string().min(1),
     title: z.string().min(1),
     description: z.string().nullable().optional(),
     imageUrl: z.string().url().nullable().optional(),
     jowUrl: z.string().url(),
     cookTimeMin: z.number().int().nullable().optional(),
     prepTimeMin: z.number().int().nullable().optional(),
     totalTimeMin: z.number().int().nullable().optional(),
     difficulty: z.string().nullable().optional(),
     instructions: z.array(z.string()).nullable().optional(),
     nutriScore: z.string().nullable().optional(),
     rating: z.number().nullable().optional(),
     ratingCount: z.number().int().nullable().optional(),
     cuisine: z.string().nullable().optional(),
     category: z.string().nullable().optional(),
     originalPortions: z.number().int().nullable().optional(),
     jowNutritionPerServing: z.record(z.number()).nullable().optional(),
     ingredients: z.array(ingredientUploadSchema).min(1),
     tags: z.array(z.string()).default([]),
   })
   ```
   - Parse body with `recipeUploadSchema.safeParse(body)`
   - Return 400 `{ error: "Validation failed", details: result.error.flatten() }` if invalid

   **Database upsert (Drizzle transaction):**
   Import `db` from `@/db` and schema tables from `@/db/schema`.

   Within a `db.transaction(async (tx) => { ... })`:

   a) **Upsert recipe:**
      ```
      tx.insert(recipes).values({
        jowId, title, description, imageUrl, jowUrl, cookTimeMin, prepTimeMin,
        totalTimeMin, difficulty, instructions, nutriScore, rating, ratingCount,
        cuisine, category, originalPortions, jowNutritionPerServing
      }).onConflictDoUpdate({
        target: recipes.jowId,
        set: { title, description, imageUrl, cookTimeMin, prepTimeMin, totalTimeMin,
               difficulty, instructions, nutriScore, rating, ratingCount, cuisine,
               category, originalPortions, jowNutritionPerServing, updatedAt: new Date() }
      }).returning({ id: recipes.id })
      ```

   b) **For each ingredient in payload:** upsert ingredient by name:
      ```
      tx.insert(ingredients).values({
        name: ing.name,
        proteinPer100g: ing.proteinPer100g,
        carbsPer100g: ing.carbsPer100g,
        fatPer100g: ing.fatPer100g,
        caloriesPer100g: ing.caloriesPer100g,
      }).onConflictDoUpdate({
        target: ingredients.name,
        set: { proteinPer100g, carbsPer100g, fatPer100g, caloriesPer100g, updatedAt: new Date() }
      }).returning({ id: ingredients.id })
      ```

   c) **Link recipe-ingredient:**
      ```
      tx.insert(recipeIngredients).values({
        recipeId: recipe.id,
        ingredientId: ingredient.id,
        quantity: ing.quantity,
        unit: ing.unit,
        originalText: ing.originalText,
      }).onConflictDoUpdate({
        target: [recipeIngredients.recipeId, recipeIngredients.ingredientId],
        set: { quantity: ing.quantity, unit: ing.unit, originalText: ing.originalText, updatedAt: new Date() }
      })
      ```

   d) **For each tag in payload:** upsert tag by name (generate slug from name: lowercase, replace spaces with dashes, remove special chars):
      ```
      tx.insert(tags).values({ name: tag, slug: slugify(tag) })
        .onConflictDoUpdate({ target: tags.name, set: { updatedAt: new Date() } })
        .returning({ id: tags.id })
      ```
      Then link via recipeTags:
      ```
      tx.insert(recipeTags).values({ recipeId: recipe.id, tagId: tag.id })
        .onConflictDoUpdate({ target: [recipeTags.recipeId, recipeTags.tagId], set: { updatedAt: new Date() } })
      ```

   **Return:** `NextResponse.json({ id: recipe.id }, { status: 201 })`

   **Error handling:**
   - Wrap transaction in try/catch
   - On DB error: return 500 `{ error: "Internal server error" }` (don't leak DB details)

   **Helper function:** `slugify(text: string): string` -- convert tag name to URL-safe slug. Inline in the file. Handles French accents (e, a, etc. -> strip diacritics via normalize("NFD").replace(/[\u0300-\u036f]/g, "")).
  </action>
  <verify>
    - File exists at `src/app/api/recipes/upload/route.ts`
    - `pnpm tsc --noEmit` passes
    - `pnpm build` succeeds (Next.js can compile the route)
    - Manual curl test (start dev server first):
      ```
      # Should return 401 (no token)
      curl -X POST http://localhost:3000/api/recipes/upload -H "Content-Type: application/json" -d '{}'

      # Should return 400 (invalid body, valid token - use the PIPELINE_TOKEN from .env)
      curl -X POST http://localhost:3000/api/recipes/upload -H "Content-Type: application/json" -H "Authorization: Bearer $TOKEN" -d '{}'

      # Should return 201 (valid payload)
      curl -X POST http://localhost:3000/api/recipes/upload -H "Content-Type: application/json" -H "Authorization: Bearer $TOKEN" -d '{"jowId":"test123","title":"Test Recipe","jowUrl":"https://jow.fr/recipes/test-test123","ingredients":[{"name":"Chicken","quantity":200,"unit":"g","originalText":"200g chicken","proteinPer100g":31,"carbsPer100g":0,"fatPer100g":3.6,"caloriesPer100g":165,"confidence":"high"}],"tags":["sans-porc"]}'
      ```
    - Second POST with same jowId returns 201 (upsert, not duplicate error)
    - `pnpm test run` passes (existing tests unbroken)
  </verify>
  <done>
    POST /api/recipes/upload endpoint validates bearer token (401 on failure), validates body with Zod (400 on failure), upserts recipe by jowId, upserts ingredients by name, links recipe-ingredients with quantities, upserts and links tags. Returns 201 with recipe ID. Idempotent: same payload twice produces same result without duplicates.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add PIPELINE_TOKEN to local .env and production environment</name>
  <files>
    .env.example
  </files>
  <action>
1. **Create or update `.env.example`** to document the PIPELINE_TOKEN variable:
   - Add line: `PIPELINE_TOKEN=your-pipeline-bearer-token-here`
   - This documents the required env var for other developers/future reference

2. **Generate a secure token for local development:**
   - Generate a random 32-char hex string: `node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"`
   - Add to local `.env` file: `PIPELINE_TOKEN={generated_token}`
   - DO NOT commit the actual `.env` file (should already be in .gitignore)

3. **Verify env validation works:**
   - `pnpm dev` should start without env validation errors (PIPELINE_TOKEN is now required)
   - If `pnpm dev` fails because PIPELINE_TOKEN is missing, add it to `.env` first

Note: The production PIPELINE_TOKEN will need to be set on the VPS. This is documented but NOT done in this task -- the user will set it when deploying. Add a note to the summary that production env needs PIPELINE_TOKEN.
  </action>
  <verify>
    - `.env.example` contains PIPELINE_TOKEN entry
    - `.env` contains PIPELINE_TOKEN with a real value
    - `pnpm dev` starts without env validation errors
    - `pnpm build` succeeds (with SKIP_ENV_VALIDATION=1 if needed for build)
  </verify>
  <done>
    PIPELINE_TOKEN is configured locally, documented in .env.example, and env validation passes. Production deployment will need the same token set in environment.
  </done>
</task>

</tasks>

<verification>
- `pnpm build` succeeds
- `pnpm test run` passes
- curl test: POST /api/recipes/upload returns 401 without token, 400 with invalid body, 201 with valid payload
- Upsert idempotency: same recipe uploaded twice produces no duplicates
- Recipe queryable in DB after upload (check via Drizzle Studio: `pnpm db:studio`)
</verification>

<success_criteria>
1. Bearer token authentication protects the endpoint
2. Zod validation rejects malformed payloads with descriptive errors
3. Recipe upserted by jowId (onConflictDoUpdate)
4. Ingredients upserted by name with macro data
5. Recipe-ingredient junction linked with quantity/unit/originalText
6. Tags upserted and linked to recipe
7. Endpoint is idempotent (same data twice = same result)
</success_criteria>

<output>
After completion, create `.planning/phases/02-recipe-data-pipeline/02-04-SUMMARY.md`
</output>
